{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the relevant packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.getcwd() \n",
    "sys.path.insert(0, \"/Users/junxiong/Documents/HOO/MFTreeSearchCV-master/\")\n",
    "# sys.path.append(\"/Users/junxiong/Documents/HOO/MFTreeSearchCV-master/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Python 2.7 reached the end of its life on January 1st, 2020. Please upgrade your Python as Python 2.7 is no longer maintained. pip 21.0 will drop support for Python 2.7 in January 2021. More details about Python 2 support in pip can be found at https://pip.pypa.io/en/latest/development/release-process/#python-2-support\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting xgboost\n",
      "  Downloading xgboost-0.82.tar.gz (665 kB)\n",
      "\u001b[K     |████████████████████████████████| 665 kB 6.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /Users/junxiong/Library/Python/2.7/lib/python/site-packages (from xgboost) (1.16.6)\n",
      "Requirement already satisfied: scipy in /Users/junxiong/Library/Python/2.7/lib/python/site-packages (from xgboost) (1.2.3)\n",
      "Building wheels for collected packages: xgboost\n",
      "  Building wheel for xgboost (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for xgboost: filename=xgboost-0.82-cp27-cp27m-macosx_10_15_x86_64.whl size=1677831 sha256=7959785f983270cdd6a59e549f5286c8333885da70342302e79b95b7a9530120\n",
      "  Stored in directory: /Users/junxiong/Library/Caches/pip/wheels/ac/4b/14/5a9e6da5b114f3d203ee2488576dfbe905193fcbee83e9fa4a\n",
      "Successfully built xgboost\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-0.82\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from sklearn.svm import SVC,SVR\n",
    "import os\n",
    "import sys\n",
    "from MFTreeSearchCV.MFTreeSearchCV import *\n",
    "from mf.mf_func import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Just listing the contents of the main code directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFHOO.py            MFTreeSearchCV.py   __init__.pyc        converters.pyc\r\n",
      "MFTreeFunction.py   MFTreeSearchCV.pyc  \u001b[34m__pycache__\u001b[m\u001b[m/\r\n",
      "MFTreeFunction.pyc  __init__.py         converters.py\r\n"
     ]
    }
   ],
   "source": [
    "%ls MFTreeSearchCV/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetching some common data-sets \n",
    "- the news group dataset will be used in this example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits,load_boston,fetch_20newsgroups\n",
    "data = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsgroups_train = fetch_20newsgroups(subset='all')\n",
    "vectorizer = TfidfVectorizer()\n",
    "features = vectorizer.fit_transform(newsgroups_train.data)\n",
    "labels = newsgroups_train.target\n",
    "#features =features.todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the features X and the target y\n",
    "- Note that there are 15076 samples in the train set\n",
    "- This will be the number of samples to be used a the highest fidelity in the next cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15076, 173762)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = features\n",
    "y = labels\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the estimator and parameters\n",
    "- As a small example we will simple tune logistic regression\n",
    "- param_dict spcifies that we will be tuning 'C' and 'penalty'\n",
    "- 'C' is a real valued parameter to be tuned in the range [1e-5,1e5] and the searching is done in the log scale\n",
    "- 'penalty' is of course a categorical parameter\n",
    "- n_jobs is the number of threads used during CV\n",
    "- cv = 3 implies 3-fold cross-validation\n",
    "- scoring is set as 'accuracy'\n",
    "- fidelity range is [500,15076], that is at the highest level we caan traain on the whole data-set while at the cheapest level we can train using only 500 samples chosen at random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = LogisticRegression() #base estimator\n",
    "param_dict = {'C':{'range':[1e-5,1e5],'scale':'log','type':'real'},\\\n",
    "              'penalty':{'range':['l1','l2'],'scale':'linear','type':'cat'}} #parameter space\n",
    "fidelity_range = [500,15076] # fidelity range, lowest fidelity uses 500 samples while the highest one uses \n",
    "#the whole dataset  \n",
    "n_jobs = 3 # number of jobs\n",
    "cv = 3 # cv level\n",
    "fixed_params = {}\n",
    "scoring = 'accuracy'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Budget\n",
    "- We set the total budget as 100 secs\n",
    "- This is may be only 3-4 times the budget required to do one single training and CV using the whole data-set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/junxiong/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/junxiong/Library/Python/2.7/lib/python/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Time without CV: ', 9.831360101699829)\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "estimator = estimator.fit(X_train,y_train)\n",
    "t2 = time.time()\n",
    "total_budget = 100 # total budget in seconds\n",
    "print('Time without CV: ', t2 - t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating an instance of the class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MFTreeSearchCV(estimator=estimator,param_dict=param_dict,scoring=scoring,\\\n",
    "                      fidelity_range=fidelity_range,unit_cost=None,\\\n",
    "                    cv=cv,  n_jobs = n_jobs,total_budget=total_budget,debug = True,fixed_params=fixed_params)\n",
    "\n",
    "## running in debug mode will display certain outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting the model or choosing the best parameter\n",
    "- Note that refit = true, which means at the end the training is done at the best parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting unit cost automatically as None was supplied\n",
      "Unit Cost:  8.09670615196\n",
      "Auto Init: \n",
      "C: 0.20886576371957724\n",
      "nu: 0.20886576371957724\n",
      "Budget Remaining: 88.2185938009\n",
      "Number of MFHOO Instances: 3\n",
      "Budget per MFHOO Instance:21.3094917817\n",
      "Running SOO number: 1 rho: 0.95 nu: 0.20886576371957724\n",
      "multi-thread search here\n",
      "finish 2222\n",
      "finish 1\n",
      "multi-thread search here\n",
      "finish 2222\n",
      "finish 1\n",
      "multi-thread search here\n",
      "finish 2222\n",
      "finish 1\n",
      "Done!\n",
      "Running SOO number: 2 rho: 0.925945462757 nu: 0.20886576371957724\n",
      "multi-thread search here\n",
      "finish 2222\n",
      "finish 1\n",
      "multi-thread search here\n",
      "finish 2222\n",
      "finish 1\n",
      "Done!\n",
      "Updating C\n",
      "C: 0.29241206920740814\n",
      "nu_max: 0.29241206920740814\n",
      "Running SOO number: 3 rho: 0.857375 nu: 0.29241206920740814\n",
      "multi-thread search here\n",
      "finish 2222\n",
      "finish 1\n",
      "multi-thread search here\n",
      "finish 2222\n",
      "finish 1\n",
      "Done!\n",
      "Updating C\n",
      "C: 0.4093768968903714\n",
      "nu_max: 0.4093768968903714\n"
     ]
    }
   ],
   "source": [
    "m = model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting using the best model, then scoring it and then displaying the best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = m.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.926525198938992"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 316.2277660168377, 'penalty': 'l2'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{u'penalty': u'l2', u'C': 5623.413251903499}</td>\n",
       "      <td>0.948063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{u'penalty': u'l2', u'C': 5623.413251903499}</td>\n",
       "      <td>0.951514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{u'penalty': u'l2', u'C': 316.2277660168377}</td>\n",
       "      <td>0.952177</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         params     score\n",
       "0  {u'penalty': u'l2', u'C': 5623.413251903499}  0.948063\n",
       "1  {u'penalty': u'l2', u'C': 5623.413251903499}  0.951514\n",
       "2  {u'penalty': u'l2', u'C': 316.2277660168377}  0.952177"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
